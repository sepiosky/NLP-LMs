{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "WO46fjUseFQU",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WO46fjUseFQU",
    "outputId": "3ab4ce7c-24ae-475c-b1a4-5e786e61cebd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "intermediate-powell",
   "metadata": {
    "id": "intermediate-powell"
   },
   "outputs": [],
   "source": [
    "import os, itertools, tqdm, codecs, random, pickle\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as D\n",
    "#DRIVE_PATH = \"/content/drive/MyDrive/NLP/HW3\"\n",
    "DRIVE_PATH = \"/Users/sepehr/Desktop/Uni/Courses/NLP/HW3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "CmEvSvXy-zYQ",
   "metadata": {
    "id": "CmEvSvXy-zYQ"
   },
   "outputs": [],
   "source": [
    "from importlib.machinery import SourceFileLoader\n",
    "ModelsModule = SourceFileLoader(\"ModelsModule\", DRIVE_PATH+'/Models.py').load_module()\n",
    "DatasetsModule = SourceFileLoader(\"DatasetsModule\", DRIVE_PATH+'/Datasets.py').load_module()\n",
    "from ModelsModule import LSTM, SiameseLSTM, myword2vec\n",
    "from DatasetsModule import MasnaviDataset, RhymeBatchSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "duplicate-baseball",
   "metadata": {
    "id": "duplicate-baseball"
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sealed-jonathan",
   "metadata": {
    "id": "sealed-jonathan"
   },
   "outputs": [],
   "source": [
    "PERSIAN_EMBEDDINGS = \"اأآبپتثجچحخدذرزژسشصضطظعغفقکگلمنوهیئ\"\n",
    "\n",
    "def do_rhyme_words(w1,w2):\n",
    "    return w1.endswith(w2) or w2.endswith(w1) or w2 == w1 or (w1[-2:]==w2[-2:] and w1[-2:]!='ست')\n",
    "\n",
    "def do_rhyme_mesras(m1, m2):\n",
    "    return do_rhyme_words( m1[-1], m2[-1] )\n",
    "\n",
    "def is_masnavi(curr_beyt, next_beyt):\n",
    "    if not do_rhyme_mesras(*curr_beyt):\n",
    "        return False\n",
    "    if (next_beyt is not None) and not do_rhyme_mesras(*next_beyt):\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def get_beyt_rhyme(mesra1, mesra2):\n",
    "    for idx in range(1,min(len(mesra1),len(mesra2))):\n",
    "        if do_rhyme_words(mesra1[-idx], mesra2[-idx]) and mesra1[-idx] != mesra2[-idx]:\n",
    "            return tuple(sorted((mesra1[-idx], mesra2[-idx])))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-assault",
   "metadata": {
    "id": "third-assault"
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xYr0D3PIABpN",
   "metadata": {
    "id": "xYr0D3PIABpN"
   },
   "source": [
    "**Skip Bellow Cells And Only Run Loader Cell**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-clause",
   "metadata": {
    "id": "selective-clause"
   },
   "outputs": [],
   "source": [
    "mesras = {}\n",
    "for filename in os.listdir(DRIVE_PATH+'/Persian_poems_corpus/normalized'):\n",
    "    mesras[filename[:-9]] = list(filter(lambda m:len(m)>2, [x.strip().split() for x in codecs.open(DRIVE_PATH+f'/Persian_poems_corpus/normalized/{filename}','rU','utf-8').readlines()]))\n",
    "with open(DRIVE_PATH+'/datasets/mesras.pickle', 'wb') as f:\n",
    "    pickle.dump(mesras, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "figured-korea",
   "metadata": {
    "id": "figured-korea"
   },
   "outputs": [],
   "source": [
    "masnavis = []\n",
    "for poet,p_mesras in mesras.items():\n",
    "    for idx in range(0,len(p_mesras),2):\n",
    "        if idx+1 >= len(p_mesras):\n",
    "            break\n",
    "        curr_beyt = (p_mesras[idx], p_mesras[idx+1])\n",
    "        next_beyt = None if idx+3 >= len(p_mesras) else (p_mesras[idx+2], p_mesras[idx+3])\n",
    "        if is_masnavi(curr_beyt, next_beyt):\n",
    "            masnavis.append(curr_beyt)\n",
    "with open(DRIVE_PATH+'/datasets/masnavis.pickle', 'wb') as f:\n",
    "    pickle.dump(masnavis, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "demonstrated-penalty",
   "metadata": {
    "id": "demonstrated-penalty"
   },
   "outputs": [],
   "source": [
    "qazals = []\n",
    "for poet,p_mesras in mesras.items():\n",
    "    idx = 0\n",
    "    while idx < len(p_mesras):\n",
    "        if idx+1 >= len(p_mesras):\n",
    "            break\n",
    "        curr_beyt = (p_mesras[idx], p_mesras[idx+1])\n",
    "        idx += 2\n",
    "        if do_rhyme_mesras(*curr_beyt):\n",
    "            qazal = [curr_beyt]\n",
    "            next_beyt = None if idx+1 >= len(p_mesras) else (p_mesras[idx], p_mesras[idx+1])\n",
    "            while (next_beyt is not None) and do_rhyme_mesras(next_beyt[1], curr_beyt[1]):\n",
    "                qazal.append(next_beyt)\n",
    "                idx+=2\n",
    "                next_beyt = None if idx+1 >= len(p_mesras) else (p_mesras[idx], p_mesras[idx+1])\n",
    "            if len(qazal) > 1:\n",
    "                qazals.append(qazal)\n",
    "with open(DRIVE_PATH+'/datasets/qazals.pickle', 'wb') as f:\n",
    "    pickle.dump(qazals, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-median",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "fifty-median"
   },
   "outputs": [],
   "source": [
    "rhymes = []\n",
    "for beyt in masnavis:\n",
    "    rhymes.append( get_beyt_rhyme(*beyt) )\n",
    "for qazal in qazals:\n",
    "    rhymes.append(get_beyt_rhyme(*qazal[0]))\n",
    "   \n",
    "    #option 1: get rhymes of each beyt with first beyt of qazal\n",
    "    for idx in range(1,len(qazal)):\n",
    "        rhymes.append( get_beyt_rhyme(qazal[0][1], qazal[idx][1]) )\n",
    "    \n",
    "    \n",
    "    # #option2: get rhymes of each beyt with next beyt of qazal\n",
    "    # for idx in range(0,len(qazal)-1):\n",
    "    #     rhymes.append( get_beyt_rhyme(qazal[idx][1], qazal[idx+1][1]) )\n",
    "    \n",
    "    # option 3: get rhymes of each pair of beyts in qazal\n",
    "#     for idx1 in range(0,len(qazal)):\n",
    "#         for idx2 in range(idx1+1,len(qazal)):\n",
    "#             rhymes.append( get_beyt_rhyme(qazal[idx1][1], qazal[idx2][1]) )\n",
    "rhymes = list(set([r for r in rhymes if (r is not None)]))\n",
    "with open(DRIVE_PATH+'/datasets/rhymes.pickle', 'wb') as f:\n",
    "    pickle.dump(rhymes, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ZGRWH6hEASlb",
   "metadata": {
    "id": "ZGRWH6hEASlb"
   },
   "source": [
    "## Datasets Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5QiK5DX9i3Em",
   "metadata": {
    "id": "5QiK5DX9i3Em"
   },
   "outputs": [],
   "source": [
    "with open(DRIVE_PATH+'/datasets/mesras.pickle', 'rb') as f:\n",
    "    mesras = pickle.load(f)\n",
    "with open(DRIVE_PATH+'/datasets/masnavis.pickle', 'rb') as f:\n",
    "    masnavis = pickle.load(f)\n",
    "with open(DRIVE_PATH+'/datasets/qazals.pickle', 'rb') as f:\n",
    "    qazals = pickle.load(f)\n",
    "with open(DRIVE_PATH+'/datasets/rhymes.pickle', 'rb') as f:\n",
    "    rhymes = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Gb2DXmVB7UE6",
   "metadata": {
    "id": "Gb2DXmVB7UE6"
   },
   "source": [
    "### Pretrained Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xu1cj7Ejln7p",
   "metadata": {
    "id": "Xu1cj7Ejln7p"
   },
   "source": [
    "word2vec is trained on ganjoor dataset. downloaded from https://github.com/amnghd/Word2vec-on-Farsi-Literature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "X6zhnhxW_jOc",
   "metadata": {
    "id": "X6zhnhxW_jOc"
   },
   "source": [
    "run pip3 install gensim==\"4.2.0\" in case of add_vector error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3xjP4eCHAYDt",
   "metadata": {
    "id": "3xjP4eCHAYDt"
   },
   "outputs": [],
   "source": [
    "#!pip3 install gensim==\"4.2.0\"\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "class LiteratureWord2Vec(object):\n",
    "    def __init__(self):\n",
    "        super(LiteratureWord2Vec, self).__init__()\n",
    "        self.corpus = KeyedVectors.load_word2vec_format(DRIVE_PATH+'/datasets/farsi_literature_word2vec_model.txt', binary=False)\n",
    "        self.emb_dim = 100\n",
    "        \n",
    "    def add_new_word(self, w):\n",
    "        emb = self.corpus['ا'].copy()\n",
    "        while self.corpus.most_similar([emb], topn=1)[0][1]>0.5:\n",
    "            emb = np.random.normal(0,1,self.emb_dim)\n",
    "        self.corpus.add_vector(w, emb) #add vecotr__setitem__(w, emb) for older versions\n",
    "        self.corpus.fill_norms(force=True) # init_sims() for older versions\n",
    "\n",
    "    def __call__(self, words, pad_to=None):\n",
    "        if isinstance(words, str):\n",
    "            words = [words]\n",
    "        embeddings = []\n",
    "        for word in words:\n",
    "            emb = None\n",
    "            if word in self.corpus:\n",
    "                emb = self.corpus[word]\n",
    "            else: # many of words not present in corpus can be synthesised from other words\n",
    "                for i in range(len(word)):\n",
    "                    if word[:i] in self.corpus and word[i:] in self.corpus:\n",
    "                        emb = self.corpus[word[:i]]+self.corpus[word[i:]]\n",
    "            if emb is None:\n",
    "                unk_emb = self.corpus['ا'].copy()\n",
    "                unk_emb[unk_emb!=0]=0 # UNK word embedding is [0 0 0 ... 0] - #TODO: its bad for cosine similarity\n",
    "                emb = unk_emb\n",
    "            embeddings.append( torch.tensor(emb, dtype=torch.float32) )\n",
    "            \n",
    "        return torch.vstack(embeddings) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-gross",
   "metadata": {
    "id": "driven-gross"
   },
   "source": [
    "### Corpus and Word Embeddings Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gCq3K_fLmD3o",
   "metadata": {
    "id": "gCq3K_fLmD3o"
   },
   "source": [
    "we use 140,000 words in \"unigrams\" as corpus (we can use downloaded word2vec which have only 70,000 words as corpus but unks increas in train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "under-utility",
   "metadata": {
    "id": "under-utility"
   },
   "outputs": [],
   "source": [
    "all_mesras = list(itertools.chain(*mesras.values()))\n",
    "unigrams = list(itertools.chain(*all_mesras))\n",
    "unigrams = list(set([w for w in unigrams]))\n",
    "\n",
    "literatureWord2Vec = LiteratureWord2Vec()\n",
    "\n",
    "special_words = [\"__PAD__\", \"__BOM__\", \"__EOM__\"]\n",
    "for w in special_words:\n",
    "    unigrams.append(w)\n",
    "    literatureWord2Vec.add_new_word(w)\n",
    "\n",
    "with open(DRIVE_PATH+'/datasets/literatureWord2Vec.pickle', 'wb') as f:\n",
    "    pickle.dump(literatureWord2Vec, f)\n",
    "with open(DRIVE_PATH+'/datasets/unigrams.pickle', 'wb') as f:\n",
    "    pickle.dump(unigrams, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "njRFZUxU0gjr",
   "metadata": {
    "id": "njRFZUxU0gjr"
   },
   "outputs": [],
   "source": [
    "with open(DRIVE_PATH+'/datasets/literatureWord2Vec.pickle', 'rb') as f:\n",
    "    literatureWord2Vec = pickle.load(f)\n",
    "with open(DRIVE_PATH+'/datasets/unigrams.pickle', 'rb') as f:\n",
    "    unigrams = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "three-selection",
   "metadata": {
    "id": "three-selection"
   },
   "source": [
    "# N-Gram Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "delayed-percentage",
   "metadata": {
    "cellView": "form",
    "id": "delayed-percentage"
   },
   "outputs": [],
   "source": [
    "#@title Default title text\n",
    "# Modified version of \n",
    "# https://github.com/joshualoehr/ngram-language-model/blob/master/language_model.py\n",
    "from itertools import product\n",
    "import math\n",
    "import nltk\n",
    "\n",
    "\n",
    "class LanguageModel(object):\n",
    "    \"\"\"An n-gram language model trained on a given corpus.\n",
    "    \n",
    "    For a given n and given training corpus, constructs an n-gram language\n",
    "    model for the corpus by:\n",
    "    1. preprocessing the corpus (adding SOS/EOS/UNK tokens)\n",
    "    2. calculating (smoothed) probabilities for each n-gram\n",
    "    Also contains methods for calculating the perplexity of the model\n",
    "    against another corpus, and for generating sentences.\n",
    "    Args:\n",
    "        train_data (list of str): list of sentences comprising the training corpus.\n",
    "        n (int): the order of language model to build (i.e. 1 for unigram, 2 for bigram, etc.).\n",
    "        laplace (int): lambda multiplier to use for laplace smoothing (default 1 for add-1 smoothing).\n",
    "    \"\"\"\n",
    "\n",
    "    SOS = \"__BOM__\"\n",
    "    EOS = \"__EOM__\"\n",
    "    UNK = \"<UNK>\"\n",
    "    \n",
    "    def __init__(self, train_data, n, laplace=1):\n",
    "        self.n = n\n",
    "        self.vocab = dict()\n",
    "        self.laplace = laplace\n",
    "        self.tokens = self.preprocess(train_data, n)\n",
    "        self.vocab  = nltk.FreqDist(self.tokens)\n",
    "        self.model  = self._create_model()\n",
    "        self.masks  = list(reversed(list(product((0,1), repeat=n))))\n",
    "\n",
    "    def _smooth(self):\n",
    "        \"\"\"Apply Laplace smoothing to n-gram frequency distribution.\n",
    "        \n",
    "        Here, n_grams refers to the n-grams of the tokens in the training corpus,\n",
    "        while m_grams refers to the first (n-1) tokens of each n-gram.\n",
    "        Returns:\n",
    "            dict: Mapping of each n-gram (tuple of str) to its Laplace-smoothed \n",
    "            probability (float).\n",
    "        \"\"\"\n",
    "        vocab_size = len(self.vocab)\n",
    "\n",
    "        n_grams = nltk.ngrams(self.tokens, self.n)\n",
    "        n_vocab = nltk.FreqDist(n_grams)\n",
    "\n",
    "        m_grams = nltk.ngrams(self.tokens, self.n-1)\n",
    "        m_vocab = nltk.FreqDist(m_grams)\n",
    "\n",
    "        def smoothed_count(n_gram, n_count):\n",
    "            m_gram = n_gram[:-1]\n",
    "            m_count = m_vocab[m_gram]\n",
    "            return (n_count + self.laplace) / (m_count + self.laplace * vocab_size)\n",
    "\n",
    "        return { n_gram: smoothed_count(n_gram, count) for n_gram, count in n_vocab.items() }\n",
    "\n",
    "    def _create_model(self):\n",
    "        \"\"\"Create a probability distribution for the vocabulary of the training corpus.\n",
    "        \n",
    "        If building a unigram model, the probabilities are simple relative frequencies\n",
    "        of each token with the entire corpus.\n",
    "        Otherwise, the probabilities are Laplace-smoothed relative frequencies.\n",
    "        Returns:\n",
    "            A dict mapping each n-gram (tuple of str) to its probability (float).\n",
    "        \"\"\"\n",
    "        if self.n == 1:\n",
    "            num_tokens = len(self.tokens)\n",
    "            return { (unigram,): count / num_tokens for unigram, count in self.vocab.items() }\n",
    "        else:\n",
    "            return self._smooth()\n",
    "\n",
    "    def _convert_oov(self, ngram):\n",
    "        \"\"\"Convert, if necessary, a given n-gram to one which is known by the model.\n",
    "        Starting with the unmodified ngram, check each possible permutation of the n-gram\n",
    "        with each index of the n-gram containing either the original token or <UNK>. Stop\n",
    "        when the model contains an entry for that permutation.\n",
    "        This is achieved by creating a 'bitmask' for the n-gram tuple, and swapping out\n",
    "        each flagged token for <UNK>. Thus, in the worst case, this function checks 2^n\n",
    "        possible n-grams before returning.\n",
    "        Returns:\n",
    "            The n-gram with <UNK> tokens in certain positions such that the model\n",
    "            contains an entry for it.\n",
    "        \"\"\"\n",
    "        mask = lambda ngram, bitmask: tuple((token if flag == 1 else \"<UNK>\" for token,flag in zip(ngram, bitmask)))\n",
    "\n",
    "        ngram = (ngram,) if type(ngram) is str else ngram\n",
    "        for possible_known in [mask(ngram, bitmask) for bitmask in self.masks]:\n",
    "            if possible_known in self.model:\n",
    "                return possible_known\n",
    "\n",
    "    def perplexity(self, test_data):\n",
    "        \"\"\"Calculate the perplexity of the model against a given test corpus.\n",
    "        \n",
    "        Args:\n",
    "            test_data (list of str): sentences comprising the training corpus.\n",
    "        Returns:\n",
    "            The perplexity of the model as a float.\n",
    "        \n",
    "        \"\"\"\n",
    "        test_tokens = self.preprocess(test_data, self.n)\n",
    "        test_ngrams = nltk.ngrams(test_tokens, self.n)\n",
    "        N = len(test_tokens)\n",
    "\n",
    "        known_ngrams  = [self._convert_oov(ngram) for ngram in test_ngrams]\n",
    "        probabilities = [self.model[ngram] for ngram in known_ngrams]\n",
    "        \n",
    "        for x,y in zip(known_ngrams, probabilities):\n",
    "            print(x,y)\n",
    "        \n",
    "        return math.exp((-1/N) * sum(map(math.log, probabilities)))\n",
    "\n",
    "    def _best_candidate(self, prev, without=[]):\n",
    "        \n",
    "        blacklist  = [LanguageModel.UNK] + without\n",
    "\n",
    "        if len(prev) < self.n:\n",
    "            prev = [LanguageModel.SOS]*(self.n-1)\n",
    "\n",
    "        candidates = list(((ngram[-1],prob) for ngram,prob in self.model.items() if ngram[:-1]==tuple(prev)))\n",
    "\n",
    "        probs = [y for x,y in candidates]\n",
    "        probs = probs/np.sum(probs)\n",
    "        words = [x for x,y in candidates]\n",
    "\n",
    "        idx = np.random.choice(len(words), 1, replace=False, p=probs)[0]\n",
    "        \n",
    "        while words[idx] in blacklist:\n",
    "            idx = np.random.choice(len(words), 1, replace=False, p=probs)[0]\n",
    "        \n",
    "        return (words[idx], probs[idx])\n",
    "         \n",
    "    def generate_sentence(self, input, min_len=12, max_len=24):\n",
    "        #sent, prob = ([LanguageModel.SOS] * (max(1, self.n-1)), 1)\n",
    "        sent, prob, start = input.copy(), 1, True\n",
    "        while sent[-1] != LanguageModel.EOS or start:\n",
    "            start = False\n",
    "            prev = () if self.n == 1 else tuple(sent[-(self.n-1):])\n",
    "            blacklist = sent + ([LanguageModel.EOS,LanguageModel.SOS] if len(sent) < min_len else [])\n",
    "            next_token, next_prob = self._best_candidate(prev, without=blacklist)\n",
    "            sent.append(next_token)\n",
    "            prob *= next_prob\n",
    "\n",
    "            if len(sent) >= max_len:\n",
    "                sent.append(LanguageModel.EOS)\n",
    "\n",
    "        #return (' '.join(sent[(self.n-1):-1]), -1/math.log(prob))\n",
    "        #return (' '.join(sent), -1/math.log(prob))\n",
    "        return ' '.join(sent)\n",
    "    \n",
    "    \n",
    "\n",
    "    def add_sentence_tokens(self, sentences, n):\n",
    "        \"\"\"Wrap each sentence in SOS and EOS tokens.\n",
    "        For n >= 2, n-1 SOS tokens are added, otherwise only one is added.\n",
    "        Args:\n",
    "            sentences (list of str): the sentences to wrap.\n",
    "            n (int): order of the n-gram model which will use these sentences.\n",
    "        Returns:\n",
    "            List of sentences with SOS and EOS tokens wrapped around them.\n",
    "        \"\"\"\n",
    "        sos = ' '.join([LanguageModel.SOS] * (n-1)) if n > 1 else LanguageModel.SOS\n",
    "        return ['{} {} {}'.format(sos, s, LanguageModel.EOS) for s in sentences]\n",
    "\n",
    "    def replace_singletons(self, tokens):\n",
    "        \"\"\"Replace tokens which appear only once in the corpus with <UNK>.\n",
    "\n",
    "        Args:\n",
    "            tokens (list of str): the tokens comprising the corpus.\n",
    "        Returns:\n",
    "            The same list of tokens with each singleton replaced by <UNK>.\n",
    "\n",
    "        \"\"\"\n",
    "        if len(self.vocab) == 0:\n",
    "            self.vocab = nltk.FreqDist(tokens)\n",
    "        return [token if self.vocab[token] > 1 else LanguageModel.UNK for token in tokens]\n",
    "\n",
    "    def preprocess(self, sentences, n):\n",
    "        \"\"\"Add SOS/EOS/UNK tokens to given sentences and tokenize.\n",
    "        Args:\n",
    "            sentences (list of str): the sentences to preprocess.\n",
    "            n (int): order of the n-gram model which will use these sentences.\n",
    "        Returns:\n",
    "            The preprocessed sentences, tokenized by words.\n",
    "        \"\"\"\n",
    "        sentences = self.add_sentence_tokens(sentences, n)\n",
    "        tokens = ' '.join(sentences).split()\n",
    "        tokens = self.replace_singletons(tokens)\n",
    "        return tokens    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "warming-entry",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = list(itertools.chain(*masnavis))\n",
    "masnavi_beyts_str = [' '.join(b[2*idx])+' __EOM__ __BOM__ '+' '.join(b[2*idx+1]) for idx in range(len(b)//2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "younger-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "masnavi_mesras_str = [' '.join(s) for s in list(itertools.chain(*masnavis))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ud_6cO0DTosZ",
   "metadata": {
    "id": "ud_6cO0DTosZ"
   },
   "outputs": [],
   "source": [
    "n_gram_model = LanguageModel(masnavi_beyts_str, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "FipOmElqTo20",
   "metadata": {
    "id": "FipOmElqTo20"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__BOM__ بی چهر او ننوشم کوثر را __EOM__ که بر سر روی خروش رخی تکیه شد گزیری بدید __EOM__'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = ['__BOM__', 'بی', 'چهر', 'او', 'ننوشم', 'کوثر', 'را', '__EOM__', ]\n",
    "n_gram_model.generate_sentence(sent, 2*len(sent)-2, 2*len(sent)+2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-recruitment",
   "metadata": {
    "id": "divine-recruitment"
   },
   "source": [
    "# Encoder - Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hWUPB78t7-R_",
   "metadata": {
    "id": "hWUPB78t7-R_"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, embeddings, hidden_dims, num_layers, dropout, device):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embeddings = embeddings\n",
    "        self.device = device\n",
    "        self.enc = LSTM(embeddings('ا').size(1), hidden_dims, num_layers, dropout, device, bidirectional=False)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embeds = torch.stack([self.embeddings(s) for s in input]).to(self.device)\n",
    "        N, L = embeds.size(0), embeds.size(1)\n",
    "        hidden, cell = self.enc.init_hidden(N)\n",
    "        output, hidden, cell = self.enc(embeds, N, hidden, cell)\n",
    "        return output, hidden, cell\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, corpus, embeddings, hidden_dims, output_dims, num_layers, dropout, device):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embeddings = embeddings\n",
    "        self.corpus = corpus\n",
    "        self.device = device\n",
    "        self.dec = LSTM(embeddings('ا').size(1), hidden_dims, num_layers, dropout, device, bidirectional=False)\n",
    "        self.output_net = nn.Sequential(\n",
    "            # nn.Linear(hidden_dims,hidden_dims),\n",
    "            # nn.ReLU(),\n",
    "            nn.Linear(hidden_dims,output_dims), #2*hidden_dim for bidirectional\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(output_dims,output_dims),\n",
    "            nn.Softmax(dim=1)\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, target, hidden, cell, teacher_force_prob=1.0):\n",
    "        target_embeds = torch.stack([self.embeddings(s) for s in target]).to(self.device)\n",
    "        N, L = target_embeds.size(0), target_embeds.size(1)\n",
    "        start_token = \"__PAD__\"\n",
    "        dec_input = torch.stack([self.embeddings(start_token)]*N)\n",
    "        dec_hidden, dec_cell = hidden, cell\n",
    "        tf = False if (teacher_force_prob < 1.0 and random.random() < 1.0-teacher_force_prob) else True\n",
    "        pred = []\n",
    "        for l in range(L):\n",
    "            dec_output, dec_hidden, dec_cell = self.dec(dec_input, N, dec_hidden, dec_cell)\n",
    "            softmax = nn.Softmax(dim=1)\n",
    "            dec_pred = softmax(self.output_net(dec_output.squeeze(dim=1)))\n",
    "            pred.append(dec_pred)\n",
    "            preds_embs =torch.stack([self.embeddings(self.corpus[idx]) for idx in dec_pred.argmax(dim=1)])\n",
    "            dec_input = target_embeds[:,l,:].unsqueeze(dim=1) if tf else preds_embs # detach from history as input\n",
    "        return torch.stack(pred)\n",
    "        \n",
    "class EncoderDecoder(nn.Module):\n",
    "    def __init__(self, corpus, embeddings, hidden_dims, output_dims, num_layers, dropout, device):\n",
    "        super(EncoderDecoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.encoder = Encoder(embeddings, hidden_dims, num_layers, dropout, device)\n",
    "        self.decoder = Decoder(corpus, embeddings, hidden_dims, output_dims, num_layers, dropout, device)\n",
    "        self.loss_fn = nn.CrossEntropyLoss(reduction=\"mean\")\n",
    "        \n",
    "    def forward(self, input, target, teacher_force_prob=1.0):\n",
    "        _, enc_hidden, enc_cell = self.encoder(input)\n",
    "        return self.decoder(target, enc_hidden, enc_cell, teacher_force_prob).transpose(0,1)\n",
    "    \n",
    "    def get_loss(self, preds, target_indices, mask):\n",
    "        mask_l = [1]*mask + [0]*(len(target_indices)-mask)\n",
    "        loss = [self.loss_fn(preds[idx].unsqueeze(dim=0), target_indices[idx].unsqueeze(dim=0))*mask_l[idx] for idx in range(len(mask_l))]\n",
    "        #loss = self.loss_fn(preds[:,0:mask], target_indices[0:mask].to(self.device))\n",
    "        return sum(loss)/len(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "variable-decimal",
   "metadata": {
    "id": "variable-decimal"
   },
   "outputs": [],
   "source": [
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "def train_encdec_model(encdec, dataLoader, encdec_optim, epochs, device):\n",
    "    encdec.train()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"=============epoch:{epoch}=============\")\n",
    "        for batch_idx, (mesras, (targets, targets_indices, masks)) in enumerate(dataLoader):\n",
    "            encdec_optim.zero_grad()\n",
    "\n",
    "            mesras = [m.split(\"#\") for m in mesras]\n",
    "            targets = [t.split(\"#\") for t in targets]\n",
    "            targets_indices = targets_indices.to(device)\n",
    "            preds = encdec(mesras, targets)\n",
    "            loss = 0\n",
    "            for idx, seq in enumerate(preds):\n",
    "                loss += encdec.get_loss(seq, targets_indices[idx], masks[idx])\n",
    "            loss.backward()\n",
    "            if batch_idx%100 ==0:\n",
    "                print(f\"batch {batch_idx} loss: {loss}\")\n",
    "                torch.save(encdec.state_dict(), DRIVE_PATH+f'/encdec_model.pt')\n",
    "            encdec_optim.step()\n",
    "            #print(prof.key_averages(group_by_stack_n=10).table(sort_by=\"self_cpu_memory_usage\", row_limit=10))\n",
    "    \n",
    "    return encdec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "hungarian-ensemble",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 632
    },
    "id": "hungarian-ensemble",
    "outputId": "a891f706-2f89-4ce7-d72a-e9ba418ea205"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============epoch:0=============\n",
      "batch 0 loss: 180.02899169921875\n",
      "batch 100 loss: 171.6228485107422\n",
      "batch 200 loss: 173.02386474609375\n",
      "batch 300 loss: 179.32843017578125\n",
      "batch 400 loss: 181.42990112304688\n",
      "batch 500 loss: 169.52134704589844\n",
      "batch 600 loss: 186.3334197998047\n",
      "batch 700 loss: 177.92739868164062\n",
      "batch 800 loss: 179.328369140625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-60a1d1db4850>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mencdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munigrams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mliteratureWord2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munigrams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencdec_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mencdec_optim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencdec_lr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mencdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_encdec_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencdec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasnaviDataLoader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencdec_optim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencdec_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencdec_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-3e96db55045b>\u001b[0m in \u001b[0;36mtrain_encdec_model\u001b[0;34m(encdec, dataLoader, encdec_optim, epochs, device)\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mmesras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmesras\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mtargets_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encdec_batch_size = 32\n",
    "encdec_epochs = 5\n",
    "encdec_lr = 0.01\n",
    "encdec_device = 'cuda:0'\n",
    "\n",
    "masnaviDataset = MasnaviDataset(masnavis, unigrams)\n",
    "masnaviDataLoader = D.DataLoader(masnaviDataset, encdec_batch_size, shuffle=True)\n",
    "encdec = EncoderDecoder(corpus=unigrams, embeddings=literatureWord2Vec, hidden_dims=1024, output_dims=len(unigrams), num_layers=3, dropout=0.3, device=encdec_device)\n",
    "encdec_optim = torch.optim.Adam(encdec.parameters(), lr=encdec_lr)\n",
    "encdec = train_encdec_model(encdec, masnaviDataLoader, encdec_optim, encdec_epochs, encdec_device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-federal",
   "metadata": {
    "id": "valued-federal"
   },
   "source": [
    "## Rhyme Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0LOVvOtn8IDo",
   "metadata": {
    "id": "0LOVvOtn8IDo"
   },
   "source": [
    "### Preparing Rhymes Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "GDzWAa6q4SI_",
   "metadata": {
    "id": "GDzWAa6q4SI_"
   },
   "outputs": [],
   "source": [
    "NON_RHYME_DATA_POINT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5mYPd0dIa2zQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "id": "5mYPd0dIa2zQ",
    "outputId": "756e79f8-18e5-45e5-e1e8-185c8ba1a402"
   },
   "outputs": [],
   "source": [
    "rhymes_dataset = [(w1,w2,1) for (w1,w2) in rhymes]\n",
    "for w1,w2 in rhymes:\n",
    "    for idx in range(NON_RHYME_DATA_POINT):\n",
    "        x = None\n",
    "        while True:\n",
    "            x = random.sample(unigrams,1)[0]\n",
    "            if not do_rhyme_words(w1,x):\n",
    "                break\n",
    "        rhymes_dataset.append( (w1,x,-1) )\n",
    "        while True:\n",
    "            x = random.sample(unigrams,1)[0]\n",
    "            if not do_rhyme_words(w2,x):\n",
    "                break\n",
    "        rhymes_dataset.append( (x,w2,-1) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "brave-development",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "brave-development",
    "outputId": "ab28584e-3c4a-4098-edac-bf0dd929fb36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('بتوان', 'مدان', 1),\n",
       " ('شاهجهان', 'پریشانم', -1),\n",
       " ('زنان', 'غمخوارش', -1),\n",
       " ('اثری', 'مستقری', 1),\n",
       " ('ست', 'سسلسله', -1)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(rhymes_dataset,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "Bn3DOTWxIQOl",
   "metadata": {
    "id": "Bn3DOTWxIQOl"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "train_length, test_length = (int)(0.95*len(rhymes_dataset)), len(rhymes_dataset)-(int)(0.95*len(rhymes_dataset))\n",
    "rhymes_dataset_train, rhymes_dataset_test = torch.utils.data.random_split(rhymes_dataset, [train_length, test_length],torch.Generator().manual_seed(seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UxsseV-f9gt4",
   "metadata": {
    "id": "UxsseV-f9gt4"
   },
   "source": [
    "### Rhymes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "collected-portable",
   "metadata": {
    "id": "collected-portable"
   },
   "outputs": [],
   "source": [
    "def run_rhyme_model(rhyme_model, data_loader, batch_size, device, train=True):\n",
    "    print(f\"Running on {device}\")\n",
    "    accs, losses = [], []\n",
    "    for idx, batch in enumerate(data_loader):\n",
    "        rhyme_model.optimizer.zero_grad() # too Result khoobe nabood =)))\n",
    "        \n",
    "        r1 = torch.vstack([myword2vec(batch[0][b]) for b in range(batch_size)]).to(device)\n",
    "        r2 = torch.vstack([myword2vec(batch[1][b]) for b in range(batch_size)]).to(device)\n",
    "        y = torch.Tensor([batch[2][b] for b in range(batch_size)]).to(device)\n",
    "        embedding1, embedding2 = rhyme_model(r1,r2,y)\n",
    "        loss = rhyme_model.get_loss(embedding1.view(batch_size,-1), embedding2.view(batch_size,-1),y)\n",
    "        losses.append(loss)\n",
    "\n",
    "        y_pred = [1 if l<0.3 else -1 for l in loss]\n",
    "        acc = sum([int(y[idx]==y_pred[idx]) for idx in range(len(y))])/len(y)\n",
    "        accs.append(acc)\n",
    "\n",
    "        if train:\n",
    "            loss = loss.mean()\n",
    "            loss.backward()\n",
    "        \n",
    "            rhyme_model.optimizer.step()\n",
    "        \n",
    "            if idx%1000 == 0:\n",
    "                print(f\"Train Loss: {loss}.         Train Acc: {acc}\")\n",
    "                torch.save(rhyme_model.state_dict(), DRIVE_PATH+f'/rhyme_models/rhyme_model{idx}.pt')\n",
    "    return accs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "OXehTuphBY7Q",
   "metadata": {
    "id": "OXehTuphBY7Q"
   },
   "outputs": [],
   "source": [
    "#!rm -rf $DRIVE_PATH/rhyme_models/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SHS8yBqK-Oma",
   "metadata": {
    "id": "SHS8yBqK-Oma"
   },
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "supported-choice",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "supported-choice",
    "outputId": "71d35e1a-67e3-46e5-d7c3-f4b9542fb929"
   },
   "outputs": [],
   "source": [
    "rhm_batch_size=256\n",
    "rhm_train_iterations = 20000 # approx 5 epoch\n",
    "rhm_device = 'cpu'\n",
    "\n",
    "rhyme_model = SiameseLSTM(embedding_dim=128, hidden_dim=512, num_layers=1, dropout=0.0, learning_rate=0.01, device=rhm_device)\n",
    "\n",
    "rhymes_train_sampler = RhymeBatchSampler(rhymes_dataset_train, npratio=0.5, iterations=rhm_train_iterations, batch_size=rhm_batch_size) #npratio=1/(1+NON_RHYME_DATA_POINT)\n",
    "rhymes_train_data_loader = torch.utils.data.DataLoader(rhymes_dataset_train, batch_sampler=rhymes_train_sampler)\n",
    "\n",
    "#train_accs, train_losses = run_rhyme_model(rhyme_model, rhymes_train_data_loader, rhm_batch_size, rhm_device, train=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "snluGkwo-R0k",
   "metadata": {
    "id": "snluGkwo-R0k"
   },
   "source": [
    "#### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "sensitive-association",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat: /Users/sepehr/Desktop/Uni/Courses/NLP/HW3/rhyme_models/rhyme_model9000.pt: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!cat $DRIVE_PATH/rhyme_models/rhyme_model19000.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6WG5weRmQUXh",
   "metadata": {
    "id": "6WG5weRmQUXh"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/sepehr/Desktop/Uni/Courses/NLP/HW3/rhyme_models/rhyme_model9000.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [79]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m rhymes_test_sampler \u001b[38;5;241m=\u001b[39m RhymeBatchSampler(rhymes_dataset_test, npratio\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39mrhm_batch_size)\n\u001b[1;32m      3\u001b[0m rhymes_test_data_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(rhymes_dataset_test, batch_sampler\u001b[38;5;241m=\u001b[39mrhymes_test_sampler)\n\u001b[0;32m----> 5\u001b[0m rhyme_model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDRIVE_PATH\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/rhyme_models/rhyme_model9000.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrhm_device\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/serialization.py:594\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    592\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 594\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    596\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    597\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    598\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    599\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/serialization.py:230\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 230\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    232\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/torch/serialization.py:211\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/sepehr/Desktop/Uni/Courses/NLP/HW3/rhyme_models/rhyme_model9000.pt'"
     ]
    }
   ],
   "source": [
    "rhyme_model = SiameseLSTM(embedding_dim=128, hidden_dim=512, num_layers=1, dropout=0.0, learning_rate=0.01, device=rhm_device)\n",
    "rhymes_test_sampler = RhymeBatchSampler(rhymes_dataset_test, npratio=0.5, iterations=2000, batch_size=rhm_batch_size)\n",
    "rhymes_test_data_loader = torch.utils.data.DataLoader(rhymes_dataset_test, batch_sampler=rhymes_test_sampler)\n",
    "\n",
    "rhyme_model.load_state_dict(torch.load(DRIVE_PATH+'/rhyme_models/rhyme_model19000.pt', map_location=torch.device(rhm_device)))\n",
    "\n",
    "# rhyme_model.eval()\n",
    "# eval_accs, eval_loss = run_rhyme_model(rhyme_model, rhymes_test_data_loader, rhm_batch_size, rhm_device, train=False)\n",
    "# print(f\"Eval Accuracy: {mean(eval_accs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aR7q1zDD1oPI",
   "metadata": {
    "id": "aR7q1zDD1oPI"
   },
   "outputs": [],
   "source": [
    "rhyme_model.predict(\"سازش\",\"بارش\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complete-objective",
   "metadata": {
    "id": "complete-objective"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "medium-county",
   "metadata": {
    "id": "medium-county"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-convertible",
   "metadata": {
    "id": "filled-convertible"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "clinical-calvin",
   "metadata": {
    "id": "clinical-calvin"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-modem",
   "metadata": {
    "id": "improved-modem"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "HW3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
