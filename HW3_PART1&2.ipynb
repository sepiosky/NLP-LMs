{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# NLP-HW3-Part1&2\n",
        "## Sepehr Ghobadi, Vida Ramezanian"
      ],
      "metadata": {
        "id": "9KF2JAHejmC7"
      },
      "id": "9KF2JAHejmC7"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO46fjUseFQU",
        "outputId": "b8f287e9-e5ee-4957-e129-ebc7d81c107c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "WO46fjUseFQU"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "intermediate-powell"
      },
      "outputs": [],
      "source": [
        "import os, itertools, tqdm, codecs, random, pickle\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as D\n",
        "DRIVE_PATH = \"/content/drive/MyDrive/NLP/HW3\""
      ],
      "id": "intermediate-powell"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "CmEvSvXy-zYQ"
      },
      "outputs": [],
      "source": [
        "from importlib.machinery import SourceFileLoader\n",
        "ModelsModule = SourceFileLoader(\"ModelsModule\", DRIVE_PATH+'/Models.py').load_module()\n",
        "DatasetsModule = SourceFileLoader(\"DatasetsModule\", DRIVE_PATH+'/Datasets.py').load_module()\n",
        "from ModelsModule import LSTM, SiameseLSTM, myword2vec\n",
        "from DatasetsModule import MasnaviDataset, RhymeBatchSampler"
      ],
      "id": "CmEvSvXy-zYQ"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install arabic_reshaper\n",
        "!pip3 install python-bidi\n",
        "import arabic_reshaper\n",
        "from matplotlib import font_manager as fm, rcParams\n",
        "from bidi.algorithm import get_display\n",
        "\n",
        "def make_farsi_text(x):\n",
        "    reshaped_text = arabic_reshaper.reshape(x)\n",
        "    farsi_text = get_display(reshaped_text)\n",
        "    return farsi_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLMXQl1we6jA",
        "outputId": "3fe29553-6341-4d34-bb83-acd7c530cdb4"
      },
      "id": "VLMXQl1we6jA",
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: arabic_reshaper in /usr/local/lib/python3.7/dist-packages (2.1.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from arabic_reshaper) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from arabic_reshaper) (57.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting python-bidi\n",
            "  Downloading python_bidi-0.4.2-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from python-bidi) (1.15.0)\n",
            "Installing collected packages: python-bidi\n",
            "Successfully installed python-bidi-0.4.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duplicate-baseball"
      },
      "source": [
        "# Utils"
      ],
      "id": "duplicate-baseball"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "sealed-jonathan"
      },
      "outputs": [],
      "source": [
        "PERSIAN_EMBEDDINGS = \"اأآبپتثجچحخدذرزژسشصضطظعغفقکگلمنوهیئ\"\n",
        "\n",
        "def do_rhyme_words(w1,w2):\n",
        "    return w1.endswith(w2) or w2.endswith(w1) or w2 == w1 or (w1[-2:]==w2[-2:] and w1[-2:]!='ست')\n",
        "\n",
        "def do_rhyme_mesras(m1, m2):\n",
        "    return do_rhyme_words( m1[-1], m2[-1] )\n",
        "\n",
        "def is_masnavi(curr_beyt, next_beyt):\n",
        "    if not do_rhyme_mesras(*curr_beyt):\n",
        "        return False\n",
        "    if (next_beyt is not None) and not do_rhyme_mesras(*next_beyt):\n",
        "        return False\n",
        "    return True\n",
        "\n",
        "def get_beyt_rhyme(mesra1, mesra2):\n",
        "    for idx in range(1,min(len(mesra1),len(mesra2))):\n",
        "        if do_rhyme_words(mesra1[-idx], mesra2[-idx]) and mesra1[-idx] != mesra2[-idx]:\n",
        "            return tuple(sorted((mesra1[-idx], mesra2[-idx])))\n",
        "    return None\n",
        "\n",
        "def vec2word(chars):\n",
        "    idx = 0\n",
        "    while(idx < len(chars)) and chars[idx]==\"__PAD__\":\n",
        "        idx+=1\n",
        "    chars = chars[idx:]\n",
        "    spec_idxs = [0]\n",
        "    for idx, c in enumerate(chars):\n",
        "        if \"_\" in c:\n",
        "            spec_idxs.append(idx)\n",
        "    spec_idxs.append(-1)\n",
        "    ans = []\n",
        "    for idx in range(len(spec_idxs)-1):\n",
        "      word = ''.join(chars[spec_idxs[idx]+1:spec_idxs[idx+1]])\n",
        "      ans.append(chars[spec_idxs[idx]])\n",
        "      if len(word)>0:\n",
        "        ans.append(word)\n",
        "    return ans"
      ],
      "id": "sealed-jonathan"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "third-assault"
      },
      "source": [
        "# Dataset"
      ],
      "id": "third-assault"
    },
    {
      "cell_type": "markdown",
      "source": [
        "در ابتدا قالب های مختلف جدا شده بودند و قصد داشتیم که مدل های مختلف را روی قالب های مختلف آموزش دهیم اما به دلیل محدودیت ها محاسباتی قادر به انجام این کار نبودیم و مدل های فقط روی اشعار فردوسی اموزش داده شده اند."
      ],
      "metadata": {
        "id": "n_vg3KbLbRnL"
      },
      "id": "n_vg3KbLbRnL"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYr0D3PIABpN"
      },
      "source": [
        "**Skip Bellow Cells And Only Run Loader Cell**"
      ],
      "id": "xYr0D3PIABpN"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "selective-clause"
      },
      "outputs": [],
      "source": [
        "mesras = {}\n",
        "for filename in os.listdir(DRIVE_PATH+'/Persian_poems_corpus/normalized'):\n",
        "    mesras[filename[:-9]] = list(filter(lambda m:len(m)>2, [x.strip().split() for x in codecs.open(DRIVE_PATH+f'/Persian_poems_corpus/normalized/{filename}','rU','utf-8').readlines()]))\n",
        "with open(DRIVE_PATH+'/datasets/mesras.pickle', 'wb') as f:\n",
        "    pickle.dump(mesras, f)"
      ],
      "id": "selective-clause"
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "figured-korea"
      },
      "outputs": [],
      "source": [
        "masnavis = []\n",
        "for poet,p_mesras in mesras.items():\n",
        "    if poet != \"ferdousi\":\n",
        "        continue\n",
        "    for idx in range(0,len(p_mesras),2):\n",
        "        if idx+1 >= len(p_mesras):\n",
        "            break\n",
        "        curr_beyt = (p_mesras[idx], p_mesras[idx+1])\n",
        "        next_beyt = None if idx+3 >= len(p_mesras) else (p_mesras[idx+2], p_mesras[idx+3])\n",
        "        if is_masnavi(curr_beyt, next_beyt):\n",
        "            masnavis.append(curr_beyt)\n",
        "with open(DRIVE_PATH+'/datasets/masnavis.pickle', 'wb') as f:\n",
        "    pickle.dump(masnavis, f)"
      ],
      "id": "figured-korea"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "demonstrated-penalty"
      },
      "outputs": [],
      "source": [
        "qazals = []\n",
        "for poet,p_mesras in mesras.items():\n",
        "    idx = 0\n",
        "    while idx < len(p_mesras):\n",
        "        if idx+1 >= len(p_mesras):\n",
        "            break\n",
        "        curr_beyt = (p_mesras[idx], p_mesras[idx+1])\n",
        "        idx += 2\n",
        "        if do_rhyme_mesras(*curr_beyt):\n",
        "            qazal = [curr_beyt]\n",
        "            next_beyt = None if idx+1 >= len(p_mesras) else (p_mesras[idx], p_mesras[idx+1])\n",
        "            while (next_beyt is not None) and do_rhyme_mesras(next_beyt[1], curr_beyt[1]):\n",
        "                qazal.append(next_beyt)\n",
        "                idx+=2\n",
        "                next_beyt = None if idx+1 >= len(p_mesras) else (p_mesras[idx], p_mesras[idx+1])\n",
        "            if len(qazal) > 1:\n",
        "                qazals.append(qazal)\n",
        "with open(DRIVE_PATH+'/datasets/qazals.pickle', 'wb') as f:\n",
        "    pickle.dump(qazals, f)"
      ],
      "id": "demonstrated-penalty"
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "fifty-median"
      },
      "outputs": [],
      "source": [
        "rhymes = []\n",
        "for beyt in masnavis:\n",
        "    rhymes.append( get_beyt_rhyme(*beyt) )\n",
        "for qazal in qazals:\n",
        "    rhymes.append(get_beyt_rhyme(*qazal[0]))\n",
        "   \n",
        "    #option 1: get rhymes of each beyt with first beyt of qazal\n",
        "    for idx in range(1,len(qazal)):\n",
        "        rhymes.append( get_beyt_rhyme(qazal[0][1], qazal[idx][1]) )\n",
        "    \n",
        "    \n",
        "    # #option2: get rhymes of each beyt with next beyt of qazal\n",
        "    # for idx in range(0,len(qazal)-1):\n",
        "    #     rhymes.append( get_beyt_rhyme(qazal[idx][1], qazal[idx+1][1]) )\n",
        "    \n",
        "    # option 3: get rhymes of each pair of beyts in qazal\n",
        "#     for idx1 in range(0,len(qazal)):\n",
        "#         for idx2 in range(idx1+1,len(qazal)):\n",
        "#             rhymes.append( get_beyt_rhyme(qazal[idx1][1], qazal[idx2][1]) )\n",
        "rhymes = list(set([r for r in rhymes if (r is not None)]))\n",
        "with open(DRIVE_PATH+'/datasets/rhymes.pickle', 'wb') as f:\n",
        "    pickle.dump(rhymes, f)"
      ],
      "id": "fifty-median"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGRWH6hEASlb"
      },
      "source": [
        "## Datasets Loader"
      ],
      "id": "ZGRWH6hEASlb"
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "5QiK5DX9i3Em"
      },
      "outputs": [],
      "source": [
        "with open(DRIVE_PATH+'/datasets/mesras.pickle', 'rb') as f:\n",
        "    mesras = pickle.load(f)\n",
        "with open(DRIVE_PATH+'/datasets/masnavis.pickle', 'rb') as f:\n",
        "    masnavis = pickle.load(f)\n",
        "with open(DRIVE_PATH+'/datasets/qazals.pickle', 'rb') as f:\n",
        "    qazals = pickle.load(f)\n",
        "with open(DRIVE_PATH+'/datasets/rhymes.pickle', 'rb') as f:\n",
        "    rhymes = pickle.load(f)"
      ],
      "id": "5QiK5DX9i3Em"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gb2DXmVB7UE6"
      },
      "source": [
        "### Chars Embedding"
      ],
      "id": "Gb2DXmVB7UE6"
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "3xjP4eCHAYDt"
      },
      "outputs": [],
      "source": [
        "#!pip3 install gensim==\"4.2.0\"\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "class CharEmbedding(object):\n",
        "    def __init__(self, corpus):\n",
        "        super(CharEmbedding, self).__init__()\n",
        "        self.corpus = corpus\n",
        "        self.emb_dim = len(corpus)\n",
        "        self.embeddings = {}\n",
        "        for idx, w in enumerate(corpus):\n",
        "            self.embeddings[w] = torch.FloatTensor([int(i == idx) for i in range(len(corpus))])\n",
        "\n",
        "    def __call__(self, words):\n",
        "        if isinstance(words, str):\n",
        "            words = [words]\n",
        "        embeddings = []\n",
        "        for word in words:\n",
        "            if word in self.embeddings:\n",
        "                embeddings.append(self.embeddings[word])\n",
        "            else:\n",
        "                embeddings.append( torch.zeros(len(self.corpus)) )\n",
        "        return torch.vstack(embeddings)"
      ],
      "id": "3xjP4eCHAYDt"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "driven-gross"
      },
      "source": [
        "### Corpus and Word Embeddings Model"
      ],
      "id": "driven-gross"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gCq3K_fLmD3o"
      },
      "source": [
        "we use 140,000 words in \"unigrams\" as corpus (we can use downloaded word2vec which have only 70,000 words as corpus but unks increas in train)"
      ],
      "id": "gCq3K_fLmD3o"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "under-utility",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "dac4a77f-dbdb-49c2-d433-02cbcd77d803"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-6d6f857ad0a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_mesras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmesras\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ferdousi\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0munigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mall_mesras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0munigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munigrams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mchar_unigrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munigrams\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"
          ]
        }
      ],
      "source": [
        "all_mesras = list(itertools.chain(*mesras[\"ferdousi\"].values()))\n",
        "unigrams = list(itertools.chain(*all_mesras))\n",
        "unigrams = list(set([w for w in unigrams]))\n",
        "char_unigrams = list(set(list(itertools.chain(*[[c for c in w] for w in unigrams]))))\n",
        "\n",
        "special_words = [\"__PAD__\", \"__BOM__\", \"__EOM__\", \"__START__\", \"__SPACE__\"]\n",
        "for w in special_words:\n",
        "    unigrams.append(w)\n",
        "    char_unigrams.append(w)\n",
        "\n",
        "with open(DRIVE_PATH+'/datasets/unigrams.pickle', 'wb') as f:\n",
        "    pickle.dump(unigrams, f)\n",
        "with open(DRIVE_PATH+'/datasets/char_unigrams.pickle', 'wb') as f:\n",
        "    pickle.dump(char_unigrams, f)"
      ],
      "id": "under-utility"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njRFZUxU0gjr"
      },
      "outputs": [],
      "source": [
        "with open(DRIVE_PATH+'/datasets/unigrams.pickle', 'rb') as f:\n",
        "    unigrams = pickle.load(f)\n",
        "with open(DRIVE_PATH+'/datasets/char_unigrams.pickle', 'rb') as f:\n",
        "    char_unigrams = pickle.load(f)"
      ],
      "id": "njRFZUxU0gjr"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Rhyme Embedding"
      ],
      "metadata": {
        "id": "IcLi1jxfWwBp"
      },
      "id": "IcLi1jxfWwBp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "برای بهبود عملکرد مدل های زبانی آموزش داده شده می توان یک مدل بدون نظارت آموزش داد تا به میزان قافیه و هم آوا بودن کلمات امتیاز دهد. به کمک این مدل می توان در خروجی مدل های زبانی که معمولا یک توزیع روی دیکشنری هستند، به جای سمپل گرفتنن محتمل ترین توکن، توکن ها را سمپل گرفت و با مدل قافیه چک کرد یا توکن با بیشترین احتمال که امتیاز هم قافیه بودن آن با ورودی از حدی بیشتر است را انتخاب کرد.\n",
        "\n",
        "آموزش این مدل هم به صورت بدون نظارت و توسط یک شبکه\n",
        "\n",
        "siamese\n",
        "\n",
        "که در سطح کاراکتر مقایسه دو شبکه ال اس تی ام را برای جفت ورودی ها شبیه سازی می کند انجام شده که لاس آن کسینوس بردار های امبدینگ جفت کلمات ورودی ضربدر لیبل آنها است. در نهایت در زمان پیش بینی میزان شباهت ۲ کلمه ضرب داخلی بردار های امبدیینگ یاد گرفته شده ی انها است. پیاده سازی این مدل در فایل\n",
        "\n",
        "Models.py/SiameseLSTM\n",
        "\n",
        "در دسترس است."
      ],
      "metadata": {
        "id": "h5H5c-YBZIii"
      },
      "id": "h5H5c-YBZIii"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Preparing Rhymes Dataset"
      ],
      "metadata": {
        "id": "LETEEl64WyAW"
      },
      "id": "LETEEl64WyAW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "به ازای هر جفت قافیه و برای هرر کلمه آن تعدادی کلمه رندوم به عنووان داده بدون قافیه به دیتاست اضافه می کنیم"
      ],
      "metadata": {
        "id": "MD7v_3T4aQXa"
      },
      "id": "MD7v_3T4aQXa"
    },
    {
      "cell_type": "code",
      "source": [
        "NON_RHYME_DATA_POINT = 1\n",
        "\n",
        "rhymes_dataset = [(w1,w2,1) for (w1,w2) in rhymes]\n",
        "for w1,w2 in rhymes:\n",
        "    for idx in range(NON_RHYME_DATA_POINT):\n",
        "        x = None\n",
        "        while True:\n",
        "            x = random.sample(unigrams,1)[0]\n",
        "            if not do_rhyme_words(w1,x):\n",
        "                break\n",
        "        rhymes_dataset.append( (w1,x,-1) )\n",
        "        while True:\n",
        "            x = random.sample(unigrams,1)[0]\n",
        "            if not do_rhyme_words(w2,x):\n",
        "                break\n",
        "        rhymes_dataset.append( (x,w2,-1) )"
      ],
      "metadata": {
        "id": "FmuSx412W1Hs"
      },
      "id": "FmuSx412W1Hs",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random.sample(rhymes_dataset,10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8-osu5kW3Hu",
        "outputId": "931b6dcc-0f4d-408d-b5ea-71a9bf4bcf31"
      },
      "id": "_8-osu5kW3Hu",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('سزاوارشان', 'بریدش', -1),\n",
              " ('سخنگوی', 'چهار', -1),\n",
              " ('داد', 'یاد', 1),\n",
              " ('جان', 'نگهبان', 1),\n",
              " ('دیرساز', 'گداز', 1),\n",
              " ('چویابد', 'ریختند', -1),\n",
              " ('همچنین', 'پرسیدنی', -1),\n",
              " ('خروش', 'مکوش', 1),\n",
              " ('لواده', 'کرانه', -1),\n",
              " ('درکنی', 'کشت', -1)]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 42\n",
        "train_length, test_length = (int)(0.95*len(rhymes_dataset)), len(rhymes_dataset)-(int)(0.95*len(rhymes_dataset))\n",
        "rhymes_dataset_train, rhymes_dataset_test = torch.utils.data.random_split(rhymes_dataset, [train_length, test_length],torch.Generator().manual_seed(seed))\n"
      ],
      "metadata": {
        "id": "Cej9qslDW7mi"
      },
      "id": "Cej9qslDW7mi",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Rhymes Model"
      ],
      "metadata": {
        "id": "y-e6C7frW9hB"
      },
      "id": "y-e6C7frW9hB"
    },
    {
      "cell_type": "code",
      "source": [
        "def run_rhyme_model(rhyme_model, data_loader, batch_size, device, train=True):\n",
        "    print(f\"Running on {device}\")\n",
        "    accs, losses = [], []\n",
        "    for idx, batch in enumerate(data_loader):\n",
        "        rhyme_model.optimizer.zero_grad()\n",
        "        \n",
        "        r1 = torch.vstack([myword2vec(batch[0][b]) for b in range(batch_size)]).to(device)\n",
        "        r2 = torch.vstack([myword2vec(batch[1][b]) for b in range(batch_size)]).to(device)\n",
        "        y = torch.Tensor([batch[2][b] for b in range(batch_size)]).to(device)\n",
        "        embedding1, embedding2 = rhyme_model(r1,r2,y)\n",
        "        loss = rhyme_model.get_loss(embedding1.view(batch_size,-1), embedding2.view(batch_size,-1),y)\n",
        "        losses.append(loss)\n",
        "\n",
        "        y_pred = [1 if l<0.3 else -1 for l in loss]\n",
        "        acc = sum([int(y[idx]==y_pred[idx]) for idx in range(len(y))])/len(y)\n",
        "        accs.append(acc)\n",
        "\n",
        "        if train:\n",
        "            loss = loss.mean()\n",
        "            loss.backward()\n",
        "        \n",
        "            rhyme_model.optimizer.step()\n",
        "        \n",
        "            if idx%1000 == 0:\n",
        "                print(f\"Train Loss: {loss}.         Train Acc: {acc}\")\n",
        "                torch.save(rhyme_model.state_dict(), DRIVE_PATH+f'/rhyme_models/rhyme_model{idx}.pt')\n",
        "    return accs, losses"
      ],
      "metadata": {
        "id": "JpvU2aV2XDdY"
      },
      "id": "JpvU2aV2XDdY",
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm -rf $DRIVE_PATH/rhyme_models/*"
      ],
      "metadata": {
        "id": "bwHucH_fXH7G"
      },
      "id": "bwHucH_fXH7G",
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Train"
      ],
      "metadata": {
        "id": "0MRxT-ImXLoB"
      },
      "id": "0MRxT-ImXLoB"
    },
    {
      "cell_type": "code",
      "source": [
        "rhm_batch_size=256\n",
        "rhm_train_iterations = 20000 # approx 5 epoch\n",
        "rhm_device = 'cpu'\n",
        "\n",
        "rhyme_model = SiameseLSTM(embedding_dim=128, hidden_dim=512, num_layers=1, dropout=0.0, learning_rate=0.01, device=rhm_device)\n",
        "\n",
        "rhymes_train_sampler = RhymeBatchSampler(rhymes_dataset_train, npratio=0.5, iterations=rhm_train_iterations, batch_size=rhm_batch_size) #npratio=1/(1+NON_RHYME_DATA_POINT)\n",
        "rhymes_train_data_loader = torch.utils.data.DataLoader(rhymes_dataset_train, batch_sampler=rhymes_train_sampler)\n",
        "\n",
        "#train_accs, train_losses = run_rhyme_model(rhyme_model, rhymes_train_data_loader, rhm_batch_size, rhm_device, train=True)\n"
      ],
      "metadata": {
        "id": "RR01xEMxXPmE"
      },
      "id": "RR01xEMxXPmE",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Eval"
      ],
      "metadata": {
        "id": "BnnRSNpNXPH8"
      },
      "id": "BnnRSNpNXPH8"
    },
    {
      "cell_type": "code",
      "source": [
        "rhyme_model = SiameseLSTM(embedding_dim=128, hidden_dim=512, num_layers=1, dropout=0.0, learning_rate=0.01, device=rhm_device)\n",
        "rhymes_test_sampler = RhymeBatchSampler(rhymes_dataset_test, npratio=0.5, iterations=2000, batch_size=rhm_batch_size)\n",
        "rhymes_test_data_loader = torch.utils.data.DataLoader(rhymes_dataset_test, batch_sampler=rhymes_test_sampler)\n",
        "\n",
        "rhyme_model.load_state_dict(torch.load(DRIVE_PATH+'/rhyme_models/rhyme_model19000.pt', map_location=torch.device(rhm_device)))\n",
        "\n",
        "# rhyme_model.eval()\n",
        "# eval_accs, eval_loss = run_rhyme_model(rhyme_model, rhymes_test_data_loader, rhm_batch_size, rhm_device, train=False)\n",
        "# print(f\"Eval Accuracy: {mean(eval_accs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46cMpZCTWtlp",
        "outputId": "ffa00144-af7d-456f-e265-46c2ea7e16b6"
      },
      "id": "46cMpZCTWtlp",
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "دقت مدل حدود ۸۰ درصد بود (البته روی دیتاست ساختگی که دقیق نیست و به صورت قانون-محور و بدون برچسب زنی از دیتا ست اشعار استخراج شده است)"
      ],
      "metadata": {
        "id": "ZeLGAxTyabfy"
      },
      "id": "ZeLGAxTyabfy"
    },
    {
      "cell_type": "code",
      "source": [
        "for batch in rhymes_test_data_loader:\n",
        "    r1 = [batch[0][b] for b in range(rhm_batch_size)]\n",
        "    r2 = [batch[1][b] for b in range(rhm_batch_size)]\n",
        "    y = [batch[2][b] for b in range(rhm_batch_size)] \n",
        "    for idx in range(10):\n",
        "        print(f\"r1: {r1[idx]}    r2:{r2[idx]}.     label:{y[idx]}.     model score:{rhyme_model.predict(r1[idx],r2[idx])}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P30Z970Xxsm",
        "outputId": "876ad07e-d19a-4c95-c724-ab6dd03fff1c"
      },
      "id": "8P30Z970Xxsm",
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "r1: ارغوان    r2:خامی.     label:-1.     model score:tensor([0.])\n",
            "r1: براورنگ    r2:پرداختن.     label:-1.     model score:tensor([3.3067e-13])\n",
            "r1: جای    r2:خدای.     label:1.     model score:tensor([1.0000])\n",
            "r1: بازارگان    r2:بیچارگان.     label:1.     model score:tensor([1.0000])\n",
            "r1: بگریختند    r2:نکشت.     label:-1.     model score:tensor([0.0136])\n",
            "r1: آذرپرست    r2:نامدار.     label:-1.     model score:tensor([0.0146])\n",
            "r1: آبروی    r2:خوی.     label:1.     model score:tensor([0.9939])\n",
            "r1: قند    r2:چونستود.     label:-1.     model score:tensor([0.6795])\n",
            "r1: برگزید    r2:سزید.     label:1.     model score:tensor([0.9994])\n",
            "r1: وار    r2:گذار.     label:1.     model score:tensor([0.9701])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "three-selection"
      },
      "source": [
        "# N-Gram Language Model"
      ],
      "id": "three-selection"
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "import math\n",
        "import nltk\n",
        "\n",
        "\n",
        "class LanguageModel(object):\n",
        "    SOS = \"__BOM__\"\n",
        "    EOS = \"__EOM__\"\n",
        "    UNK = \"<UNK>\"\n",
        "    \n",
        "    def __init__(self, train_data, n, laplace=1):\n",
        "        self.n = n\n",
        "        self.vocab = dict()\n",
        "        self.laplace = laplace\n",
        "        self.tokens = self.preprocess(train_data, n)\n",
        "        self.vocab  = nltk.FreqDist(self.tokens)\n",
        "        self.model  = self._create_model()\n",
        "        self.masks  = list(reversed(list(product((0,1), repeat=n))))\n",
        "\n",
        "    def _smooth(self):\n",
        "        vocab_size = len(self.vocab)\n",
        "\n",
        "        n_grams = nltk.ngrams(self.tokens, self.n)\n",
        "        n_vocab = nltk.FreqDist(n_grams)\n",
        "\n",
        "        m_grams = nltk.ngrams(self.tokens, self.n-1)\n",
        "        m_vocab = nltk.FreqDist(m_grams)\n",
        "\n",
        "        def smoothed_count(n_gram, n_count):\n",
        "            m_gram = n_gram[:-1]\n",
        "            m_count = m_vocab[m_gram]\n",
        "            return (n_count + self.laplace) / (m_count + self.laplace * vocab_size)\n",
        "\n",
        "        return { n_gram: smoothed_count(n_gram, count) for n_gram, count in n_vocab.items() }\n",
        "\n",
        "    def _create_model(self):\n",
        "        if self.n == 1:\n",
        "            num_tokens = len(self.tokens)\n",
        "            return { (unigram,): count / num_tokens for unigram, count in self.vocab.items() }\n",
        "        else:\n",
        "            return self._smooth()\n",
        "\n",
        "    def _convert_oov(self, ngram):\n",
        "        mask = lambda ngram, bitmask: tuple((token if flag == 1 else \"<UNK>\" for token,flag in zip(ngram, bitmask)))\n",
        "\n",
        "        ngram = (ngram,) if type(ngram) is str else ngram\n",
        "        for possible_known in [mask(ngram, bitmask) for bitmask in self.masks]:\n",
        "            if possible_known in self.model:\n",
        "                return possible_known\n",
        "\n",
        "    def perplexity(self, test_data):\n",
        "        test_tokens = self.preprocess(test_data, self.n)\n",
        "        test_ngrams = nltk.ngrams(test_tokens, self.n)\n",
        "        N = len(test_tokens)\n",
        "\n",
        "        known_ngrams  = [self._convert_oov(ngram) for ngram in test_ngrams]\n",
        "        probabilities = [self.model[ngram] for ngram in known_ngrams]\n",
        "        \n",
        "        # for x,y in zip(known_ngrams, probabilities):\n",
        "        #     print(x,y)\n",
        "        \n",
        "        return math.exp((-1/N) * sum(map(math.log, probabilities)))\n",
        "\n",
        "    def _best_candidate(self, prev, without=[]):\n",
        "        \n",
        "        blacklist  = [LanguageModel.UNK] + without\n",
        "\n",
        "        if len(prev) < self.n:\n",
        "            prev = [LanguageModel.SOS]*(self.n-1)\n",
        "\n",
        "        candidates = list(((ngram[-1],prob) for ngram,prob in self.model.items() if ngram[:-1]==tuple(prev)))\n",
        "\n",
        "        probs = [y for x,y in candidates]\n",
        "        probs = probs/np.sum(probs)\n",
        "        words = [x for x,y in candidates]\n",
        "\n",
        "        idx = np.random.choice(len(words), 1, replace=False, p=probs)[0]\n",
        "        \n",
        "        while words[idx] in blacklist:\n",
        "            idx = np.random.choice(len(words), 1, replace=False, p=probs)[0]\n",
        "        \n",
        "        return (words[idx], probs[idx])\n",
        "         \n",
        "    def generate_sentence(self, input, min_len=12, max_len=24):\n",
        "        #sent, prob = ([LanguageModel.SOS] * (max(1, self.n-1)), 1)\n",
        "        sent, prob, start = input.copy(), 1, True\n",
        "        while sent[-1] != LanguageModel.EOS or start:\n",
        "            start = False\n",
        "            prev = () if self.n == 1 else tuple(sent[-(self.n-1):])\n",
        "            blacklist = sent + ([LanguageModel.EOS,LanguageModel.SOS] if len(sent) < min_len else [])\n",
        "            next_token, next_prob = self._best_candidate(prev, without=blacklist)\n",
        "            sent.append(next_token)\n",
        "            prob *= next_prob\n",
        "\n",
        "            if len(sent) >= max_len:\n",
        "                sent.append(LanguageModel.EOS)\n",
        "\n",
        "        #return (' '.join(sent[(self.n-1):-1]), -1/math.log(prob))\n",
        "        #return (' '.join(sent), -1/math.log(prob))\n",
        "        return ' '.join(sent)\n",
        "    \n",
        "    \n",
        "\n",
        "    def add_sentence_tokens(self, sentences, n):\n",
        "        sos = ' '.join([LanguageModel.SOS] * (n-1)) if n > 1 else LanguageModel.SOS\n",
        "        return ['{} {} {}'.format(sos, s, LanguageModel.EOS) for s in sentences]\n",
        "\n",
        "    def replace_singletons(self, tokens):\n",
        "        if len(self.vocab) == 0:\n",
        "            self.vocab = nltk.FreqDist(tokens)\n",
        "        return [token if self.vocab[token] > 1 else LanguageModel.UNK for token in tokens]\n",
        "\n",
        "    def preprocess(self, sentences, n):\n",
        "        sentences = self.add_sentence_tokens(sentences, n)\n",
        "        tokens = ' '.join(sentences).split()\n",
        "        tokens = self.replace_singletons(tokens)\n",
        "        return tokens    "
      ],
      "metadata": {
        "id": "p_JM2JvcLxVc"
      },
      "id": "p_JM2JvcLxVc",
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "b = list(itertools.chain(*masnavis))\n",
        "masnavi_beyts_str = [' '.join(b[2*idx])+' __EOM__ __BOM__ '+' '.join(b[2*idx+1]) for idx in range(len(b)//2)]\n",
        "masnavi_beyts_str[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6XzHAWnWaxTF",
        "outputId": "824540f7-0c47-4f78-8146-55adda70746a"
      },
      "id": "6XzHAWnWaxTF",
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'به نام خداوند جان و خرد __EOM__ __BOM__ کزین برتر اندیشه برنگذرد'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "masnavi_betys_train = masnavi_beyts_str[:int(0.9*len(masnavi_beyts_str))]\n",
        "masnavi_betys_test = masnavi_beyts_str[int(0.9*len(masnavi_beyts_str)):]"
      ],
      "metadata": {
        "id": "OecKsEXIccqO"
      },
      "id": "OecKsEXIccqO",
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "حال عملکرد مدل به ازای طول های مختلف ترکیبات را بررسی میکنیم:"
      ],
      "metadata": {
        "id": "2Kj5jED1a8nI"
      },
      "id": "2Kj5jED1a8nI"
    },
    {
      "cell_type": "code",
      "source": [
        "for n in [1,2,3,4,5]:\n",
        "    print(f\"\\n ======== N-Gram Model:  n={n} ======== \\n\")\n",
        "    n_gram_model = LanguageModel(masnavi_betys_train, n)\n",
        "    sample_beyts = np.random.choice(masnavi_betys_test,3)\n",
        "    for sbeyt in sample_beyts:\n",
        "        first_mesra_tokens = sbeyt.split(\" \")[0:sbeyt.split(\" \").index(\"__EOM__\")]\n",
        "        print(\"input: \",\" \".join(first_mesra_tokens))\n",
        "        print(\"model output:\")\n",
        "        print(n_gram_model.generate_sentence(first_mesra_tokens, 2*len(first_mesra_tokens)-2, 2*len(first_mesra_tokens)+2))\n",
        "    print(f\"\\n perplexity of {n}-gram: {n_gram_model.perplexity(masnavi_betys_test)} \\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVWX4Vboaxea",
        "outputId": "f060a23b-0e3e-442e-f3db-7a7c309c1aa8"
      },
      "id": "JVWX4Vboaxea",
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ======== N-Gram Model:  n=1 ======== \n",
            "\n",
            "input:  علم معنی را زمعنیها بپرس\n",
            "model output:\n",
            "علم معنی را زمعنیها بپرس است درمانده زبان گشته از __BOM__ آن __EOM__\n",
            "input:  مرد باید خواه خاص و خواه عام\n",
            "model output:\n",
            "مرد باید خواه خاص و خواه عام از اندازم چو دریغ قارن پیمودن پس آورد __BOM__ __EOM__\n",
            "input:  روز و شب در خدمتش بودند شاد\n",
            "model output:\n",
            "روز و شب در خدمتش بودند شاد من معنی چارپای بسان گشاید روح که __EOM__\n",
            "\n",
            " perplexity of 1-gram: 460.6800640577724 \n",
            "\n",
            "\n",
            " ======== N-Gram Model:  n=2 ======== \n",
            "\n",
            "input:  او بسگ داد آن همه تا سگ بخورد\n",
            "model output:\n",
            "او بسگ داد آن همه تا سگ بخورد به پرستنده ببسته موج همی ور ماه کن اهل شده __EOM__\n",
            "input:  چون خریدن را سزایی خون بود\n",
            "model output:\n",
            "چون خریدن را سزایی خون بود عقل بدو دلم پایی شرابی خانه ز سلک __EOM__\n",
            "input:  جوهری یابی ز استغنای حق\n",
            "model output:\n",
            "جوهری یابی ز استغنای حق نه کارنامه فرود ای یعنی خرد تو __EOM__\n",
            "\n",
            " perplexity of 2-gram: 503.59973645029254 \n",
            "\n",
            "\n",
            " ======== N-Gram Model:  n=3 ======== \n",
            "\n",
            "input:  روی زردم زین غم و جامه کبود\n",
            "model output:\n",
            "روی زردم زین غم و جامه کبود شود زبان رموزی مجنون موم گرفتی حقیقت شبان حذر __EOM__\n",
            "input:  تا بدان هر گوش در لیل ونهار\n",
            "model output:\n",
            "تا بدان هر گوش در لیل ونهار گفتا دست یکی شه ندا به بروی پیلتن مکن __EOM__\n",
            "input:  بود اندر عهد او پیغامبری\n",
            "model output:\n",
            "بود اندر عهد او پیغامبری فراموش زین قضا نگردد عاشقان که چه __EOM__\n",
            "\n",
            " perplexity of 3-gram: 1351.6213234305849 \n",
            "\n",
            "\n",
            " ======== N-Gram Model:  n=4 ======== \n",
            "\n",
            "input:  ذنب چیست از راه سر پیچیدنست\n",
            "model output:\n",
            "ذنب چیست از راه سر پیچیدنست کسی مگویید دگر در چو شکلی بیابان با __EOM__\n",
            "input:  ناگهی سیلاب محنت در رسید\n",
            "model output:\n",
            "ناگهی سیلاب محنت در رسید گذار خاست به خدنگ بودیم سوی مدتی __EOM__\n",
            "input:  چون بستاریت دیدم کارساز\n",
            "model output:\n",
            "چون بستاریت دیدم کارساز چو با شربت آفتابی غریب شده __EOM__\n",
            "\n",
            " perplexity of 4-gram: 1638.5107276098806 \n",
            "\n",
            "\n",
            " ======== N-Gram Model:  n=5 ======== \n",
            "\n",
            "input:  خشم خود را گر فرو نخورد کسی\n",
            "model output:\n",
            "خشم خود را گر فرو نخورد کسی رمیده از کتابی چو مرا ز به همیدون چون __EOM__\n",
            "input:  گفت عمری برگذشت ای نامدار\n",
            "model output:\n",
            "گفت عمری برگذشت ای نامدار ورا چو هیچ زین زمانه ز طلسمت __EOM__\n",
            "input:  ناگهی از حضرت عزت ز ذات\n",
            "model output:\n",
            "ناگهی از حضرت عزت ز ذات شاخ صورت بگو چو تو گفت مرا سوده __EOM__\n",
            "\n",
            " perplexity of 5-gram: 2174.980355674302 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "همانگونه که میبینیم با افزایش طول کانتکست، کیفییت ممکن است افزایش یابد اما نیاز به دیتا ست مناسب برای جلوگیری از اورفیتینگ وجود دارد. در کل کیفییت ایین مدل نمی تواند در تشخیص کانتکتس و تولید مصراع مناسب با مدل هایی مبتنی برشبکه های عصبی رقابت کند"
      ],
      "metadata": {
        "id": "Pg6FjXmxj78n"
      },
      "id": "Pg6FjXmxj78n"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GWwVd0mpj7YJ"
      },
      "id": "GWwVd0mpj7YJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "WYvty4xyaxlS"
      },
      "id": "WYvty4xyaxlS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "divine-recruitment"
      },
      "source": [
        "# Encoder - Decoder"
      ],
      "id": "divine-recruitment"
    },
    {
      "cell_type": "markdown",
      "source": [
        "پیاده سازی مدل انکدر-دیکدر به روش های مختلفی انجام شد. از تکنیک های مختلف مکانیزم اتنشن مانند \n",
        "\n",
        "bahdanau\n",
        "\n",
        "تا معماری های ال اس تی ام ماند چند لایه بودن یا دو طرفه بودن. همچنین برای تبدیل های ورودی و خروجی از تبدیل های خطی و همچنین شبکه های عصبی چند لایه استفاده شد.\n",
        "مقادیر مختلف هایپر پارامتر بررای نرخ یادگیری و حد برش گرادیان ها استفاده شد اما متاسفانه باگ موجود در مدل که احتمالا در قسمت حاسبه لاس اتفاق می افتد را پیدا نکردیم."
      ],
      "metadata": {
        "id": "QK7yvCh5g9lO"
      },
      "id": "QK7yvCh5g9lO"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hWUPB78t7-R_"
      },
      "outputs": [],
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, embed_dims, hidden_dims, num_layers, dropout, device):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.device = device\n",
        "        self.enc = LSTM(embed_dims, hidden_dims, num_layers, dropout, device, bidirectional=True)\n",
        "\n",
        "    def forward(self, input):\n",
        "        N, L = input.size(0), input.size(1)\n",
        "        hidden, cell = self.enc.init_hidden(N)\n",
        "        output, hidden, cell = self.enc(input, N, hidden, cell)\n",
        "        return output, hidden, cell\n",
        "    \n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, corpus, emb_dims, hidden_dims, output_dims, num_layers, dropout, device):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.corpus = corpus\n",
        "        self.device = device\n",
        "        self.emb_dims = emb_dims\n",
        "        self.dec = LSTM(emb_dims, 2*hidden_dims, num_layers, dropout=0.0, device=device, bidirectional=False)\n",
        "        self.output_net = nn.Linear(4*hidden_dims,output_dims).to(device)\n",
        "        # self.output_net = nn.Sequential( \n",
        "        #     nn.Linear(4*hidden_dims,4*hidden_dims),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.Linear(4*hidden_dims,output_dims),\n",
        "        #   ).to(device)\n",
        "\n",
        "        self.q_att = nn.Linear(4*hidden_dims,2*hidden_dims).to(device)\n",
        "        # self.q_att = nn.Sequential( \n",
        "        #     nn.Linear(4*hidden_dims,4*hidden_dims),\n",
        "        #     nn.ReLU(),\n",
        "        #     nn.Linear(4*hidden_dims,2*hidden_dims),\n",
        "        #   ).to(device)\n",
        "        self.v_att = torch.nn.Parameter(torch.FloatTensor(2*hidden_dims)).to(device)\n",
        "        torch.nn.init.normal_(self.v_att)\n",
        "\n",
        "    def forward(self, dec_input, enc_outputs, hidden, cell):\n",
        "        N = dec_input.size(0)\n",
        "        dec_output, dec_hidden, dec_cell = self.dec(dec_input, N, hidden, cell)\n",
        "\n",
        "        e_att = torch.cat((enc_outputs, dec_output.expand_as(enc_outputs)), dim=2)\n",
        "        att_weights = torch.sum(self.v_att * torch.tanh(self.q_att(e_att)), dim=2)\n",
        "        att_context = torch.bmm(att_weights.unsqueeze(1), enc_outputs).squeeze(1)\n",
        "        dec_output = torch.cat([att_context, dec_output.squeeze(dim=1)], dim=-1)\n",
        "\n",
        "        softmax = nn.Softmax(dim=-1)\n",
        "        dec_pred = softmax(self.output_net(dec_output))\n",
        "        return dec_pred, dec_hidden, dec_cell\n",
        "        \n",
        "class EncoderDecoder(nn.Module):\n",
        "    def __init__(self, corpus, input_dims, emb_dims, hidden_dims, output_dims, num_layers, dropout, device):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.device = device\n",
        "        self.corpus = corpus\n",
        "        self.input_dims = input_dims\n",
        "        self.emb_dims = emb_dims\n",
        "        self.embedding = nn.Sequential( nn.Linear(self.input_dims, self.emb_dims) ).to(device)\n",
        "        self.encoder = Encoder(self.emb_dims, hidden_dims, num_layers, dropout, device)\n",
        "        self.decoder = Decoder(corpus, self.emb_dims, hidden_dims, output_dims, num_layers, dropout, device)\n",
        "        self.loss_fn = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "        \n",
        "    def forward(self, input, target, target_mask, teacher_force_prob=1.0):\n",
        "        input = self.embedding(input)\n",
        "        enc_outputs, enc_hidden, enc_cell = self.encoder(input)\n",
        "        enc_hidden = torch.hstack([*torch.split(enc_hidden, 2, dim=0)[0]]).unsqueeze(0)\n",
        "        enc_cell = torch.hstack([*torch.split(enc_cell, 2, dim=0)[0]]).unsqueeze(0)\n",
        "        \n",
        "            \n",
        "        N, L = target.size(0), target.size(1)\n",
        "        start_token = \"__BOM__\"\n",
        "        dec_input = torch.stack([torch.Tensor([self.corpus.index(start_token)]*N)]).transpose(0,1).unsqueeze(dim=-1).to(self.device)\n",
        "        dec_hidden, dec_cell = enc_hidden, enc_cell\n",
        "        pred = []\n",
        "        loss = 0\n",
        "        for l in range(1,L):\n",
        "            dec_input = self.embedding(dec_input)\n",
        "            dec_output, dec_hidden, dec_cell = self.decoder(dec_input, enc_outputs, dec_hidden, dec_cell)\n",
        "            next_char = dec_output.argmax(dim=-1).float() #.view(-1,1,self.emb_dims)\n",
        "            pred.append(next_char)\n",
        "            step_loss = self.loss_fn(dec_output, target[:,l,:].squeeze(dim=1).type(torch.LongTensor).to(self.device))\n",
        "            step_loss = [ls*int(l<target_mask[idx]) for idx, ls in enumerate(step_loss)]\n",
        "            loss += sum(step_loss)\n",
        "            tf = False if (teacher_force_prob < 1.0 and random.random() < 1.0-teacher_force_prob) else True\n",
        "            dec_input = target[:,l,:].unsqueeze(dim=1) if tf else next_char.view(-1,1,1)\n",
        "\n",
        "        return loss, torch.stack(pred)"
      ],
      "id": "hWUPB78t7-R_"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "variable-decimal"
      },
      "outputs": [],
      "source": [
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "from tqdm import tqdm\n",
        "\n",
        "def train_encdec_model(encdec, dataLoaderTrain, datasetVal, encdec_optim, epochs, device):\n",
        "    encdec.train()\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"=============epoch:{epoch}=============\")\n",
        "        for batch_idx, (mesras, (targets, targets_indices, masks)) in enumerate(dataLoaderTrain):\n",
        "            encdec_optim.zero_grad()\n",
        "\n",
        "            char_embeddings = CharEmbedding(char_unigrams)\n",
        "            mesras = [m.split(\"#\") for m in mesras]\n",
        "            mesras = torch.stack([torch.Tensor([char_unigrams.index(c) for c in w]) for w in mesras]).unsqueeze(-1).to(device)\n",
        "            targets = [t.split(\"#\") for t in targets]\n",
        "            targets = torch.stack([torch.Tensor([char_unigrams.index(c) for c in w]) for w in targets]).unsqueeze(-1).to(device)\n",
        "            targets_indices = targets_indices.to(device)\n",
        "\n",
        "            loss, preds = encdec(mesras, targets, masks, teacher_force_prob=1.0)\n",
        "            loss.backward()\n",
        "            grads_zero = False\n",
        "            for n, p in encdec.named_parameters():\n",
        "              if not p.grad.any():\n",
        "                grads_zero = True\n",
        "            if grads_zero:\n",
        "              print(\"grads zero?:\", grads_zero)\n",
        "\n",
        "            nn.utils.clip_grad_norm_(encdec.parameters(), 0.1)\n",
        "            #nn.utils.clip_grad_norm_(encdec.parameters(), -0.4)\n",
        "            encdec_optim.step()\n",
        "            if batch_idx%100 ==0:\n",
        "                print(f\"batch {batch_idx} loss: {loss/preds.size(0)}\")\n",
        "                idx_val = np.random.randint(0, len(datasetVal))\n",
        "                with torch.no_grad():\n",
        "                  eval_mesra, eval_target = datasetVal[idx_val][0].split(\"#\"), datasetVal[idx_val][1][0].split(\"#\")\n",
        "                  eval_mesra = torch.stack([torch.Tensor([char_unigrams.index(c) for c in eval_mesra])]).unsqueeze(-1).to(device)\n",
        "                  eval_target = torch.stack([torch.Tensor([char_unigrams.index(c) for c in eval_target])]).unsqueeze(-1).to(device)\n",
        "                  mask = [datasetVal[idx_val][1][2]]\n",
        "\n",
        "                  _, preds = encdec(eval_mesra, eval_target, mask, teacher_force_prob=0.0)\n",
        "                  print(\"input:\", vec2word(datasetVal[idx_val][0].split(\"#\")))\n",
        "                  print(\"predict:\", vec2word([char_unigrams[int(c.item())] for c in preds]))\n",
        "                torch.save(encdec.state_dict(), DRIVE_PATH+f'/encdec_model_ferdousi.pt')\n",
        "            #print(prof.key_averages(group_by_stack_n=10).table(sort_by=\"self_cpu_memory_usage\", row_limit=10))\n",
        "\n",
        "    return encdec"
      ],
      "id": "variable-decimal"
    },
    {
      "cell_type": "code",
      "source": [
        "encdec_batch_size = 128\n",
        "encdec_epochs = 150\n",
        "encdec_lr = 0.01\n",
        "encdec_device = 'cuda:0'\n",
        "\n",
        "masnaviDatasetTrain = MasnaviDataset(masnavis[:int(0.9*len(masnavis))], char_unigrams)\n",
        "masnaviDatasetVal = MasnaviDataset(masnavis[int(0.9*len(masnavis)):], char_unigrams)\n",
        "\n",
        "masnaviDataLoaderTrain = D.DataLoader(masnaviDatasetTrain, encdec_batch_size, shuffle=True)\n",
        "masnaviDataLoaderVal = D.DataLoader(masnaviDatasetVal, encdec_batch_size, shuffle=True)\n",
        "\n",
        "encdec = EncoderDecoder(corpus=char_unigrams, input_dims=1, emb_dims=64, hidden_dims=1024, output_dims=len(char_unigrams), num_layers=1, dropout=0.0, device=encdec_device)\n",
        "encdec_optim = torch.optim.Adadelta(encdec.parameters(), lr=encdec_lr, rho=0.95, eps=1e-6)\n",
        "#encdec_optim = torch.optim.SGD(encdec.parameters(), lr=encdec_lr)\n",
        "encdec = train_encdec_model(encdec, masnaviDataLoaderTrain, masnaviDatasetVal, encdec_optim, encdec_epochs, encdec_device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 856
        },
        "id": "Sd7qwnbO1O39",
        "outputId": "2e510fda-81b6-4969-9d7d-f5891e61a234"
      },
      "id": "Sd7qwnbO1O39",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=============epoch:0=============\n",
            "batch 0 loss: 200.58827209472656\n",
            "input: ['__BOM__', '__BOM__', 'همه', '__SPACE__', 'مهتران', '__SPACE__', 'پشت', '__SPACE__', 'برگاشتند', '__EOM__']\n",
            "predict: ['ا', 'اااااااااااااااااااااااجاجاجاجانننننننننننننههههههههههههه']\n",
            "batch 100 loss: 200.1668701171875\n",
            "input: ['__BOM__', '__BOM__', 'سپاهی', '__SPACE__', 'بران', '__SPACE__', 'گونه', '__SPACE__', 'کردی', '__SPACE__', 'تباه', '__EOM__']\n",
            "predict: ['ا', 'اااااااااااااااااااااا', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', 'ن', '__EOM__', 'ن', '__EOM__', 'هننن', '__EOM__', 'نننننننههههههههههههه']\n",
            "batch 200 loss: 199.24209594726562\n",
            "input: ['__BOM__', '__BOM__', 'یکایک', '__SPACE__', 'همه', '__SPACE__', 'کار', '__SPACE__', 'او', '__SPACE__', 'را', '__SPACE__', 'بساخت', '__EOM__']\n",
            "predict: ['ا', 'اااااااااااااااااااا', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__']\n",
            "=============epoch:1=============\n",
            "batch 0 loss: 199.16441345214844\n",
            "input: ['__BOM__', '__BOM__', 'بیاورد', '__SPACE__', 'سیصد', '__SPACE__', 'شتر', '__SPACE__', 'سرخ', '__SPACE__', 'موی', '__EOM__']\n",
            "predict: ['ا', 'اااااااااااااااااااااا', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__']\n",
            "batch 100 loss: 196.35658264160156\n",
            "input: ['__BOM__', '__BOM__', 'ز', '__SPACE__', 'جم', '__SPACE__', 'و', '__SPACE__', 'فریدون', '__SPACE__', 'چو', '__SPACE__', 'ایشان', '__SPACE__', 'نزاد', '__EOM__']\n",
            "predict: ['ا', 'ااااااااااااااااااااا', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__']\n",
            "batch 200 loss: 197.79283142089844\n",
            "input: ['__BOM__', '__BOM__', 'چو', '__SPACE__', 'آگاهی', '__SPACE__', 'آمد', '__SPACE__', 'سوی', '__SPACE__', 'پهلوان', '__EOM__']\n",
            "predict: ['ا', 'اااااااااااااااااااااا', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__']\n",
            "=============epoch:2=============\n",
            "batch 0 loss: 199.45347595214844\n",
            "input: ['__BOM__', '__BOM__', 'به', '__SPACE__', 'بیگانگان', '__SPACE__', 'هم', '__SPACE__', 'نشاید', '__SPACE__', 'بنیز', '__EOM__']\n",
            "predict: ['ا', 'ااااااااااااااااااااا', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__', '__EOM__']\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-bd5052d1666e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mencdec_optim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdadelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencdec_lr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrho\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m#encdec_optim = torch.optim.SGD(encdec.parameters(), lr=encdec_lr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mencdec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_encdec_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencdec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasnaviDataLoaderTrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasnaviDatasetVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencdec_optim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencdec_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencdec_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-28-0e34ceb58af0>\u001b[0m in \u001b[0;36mtrain_encdec_model\u001b[0;34m(encdec, dataLoaderTrain, datasetVal, encdec_optim, epochs, device)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencdec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmesras\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteacher_force_prob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mgrads_zero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mencdec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_parameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ubdRvrfbSpeq"
      },
      "id": "ubdRvrfbSpeq"
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HhJYd6lCSpmC"
      },
      "id": "HhJYd6lCSpmC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "fmNI_ctzSpsZ"
      },
      "id": "fmNI_ctzSpsZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "improved-modem"
      },
      "outputs": [],
      "source": [
        ""
      ],
      "id": "improved-modem"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "HW3-PART1&2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}